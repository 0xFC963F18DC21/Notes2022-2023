# Recursive Types

Let us try to express lists.

We could say it's a pair of an element, and a list, or an empty list constant. So how do we bake this into types (as this is a recursive definition)?

So what is a pair?

We can express it as a polytype of $A \times B$, and we can express disjoint choice using $A + B$.

Let's make some assignment rules for it, in the context of $ML$ (but you can really use it on any other system if you want).

Note that $\left< E_1, E_2 \right>$, $\text{Right}(E)$, and $\text{Left}(E)$ are terms.
$$\dfrac{
    \Gamma \vdash E_1 : A
    \hspace{2em}
    \Gamma \vdash E_2 : B
}{
    \Gamma \vdash \left< E_1, E_2 \right> : A \times B
}$$
$$\dfrac{
    \Gamma \vdash E : A \times B
}{
    \Gamma \vdash \text{Right}(E) : B
}
\text{ and }
\dfrac{
    \Gamma \vdash E : A \times B
}{
    \Gamma \vdash \text{Left}(E) : A
}$$
We also need some reduction rules for these new constructs:
$$\begin{align*}
    \text{Left}(\left< E_1, E_2 \right>) &\to E_1 \\
    \text{Right}(\left< E_1, E_2 \right>) &\to E_2
\end{align*}$$
We also need some contextual rules, allowing you to run the contents of a pair.

In our case, $\text{Left}$ and $\text{Right}$ are functions. It is only when they are applied to an expression that the overall thing becomes a term.

Polytypes ($\times$) will let us build pairs and lists.

Choice / or-types are a little harder... let's borrow or-introduction from logic:
$$
\dfrac{
    \Gamma \vdash E : A
}{
    \Gamma \vdash \text{inj. }\mathcal{l}\left< E \right> : A + B
}
\text{ and }
\dfrac{
    \Gamma \vdash E : B
}{
    \Gamma \vdash \text{inj. }\mathcal{r}\left< E \right> : A + B
}
$$
What about using these types? Let's borrow from logic again with or-elimination:
$$\dfrac{
    \Gamma \vdash E : A + B
    \hspace{2em}
    \Gamma \vdash E_1 : A \to C
    \hspace{2em}
    \Gamma \vdash E_2 : B \to C
}{
    \Gamma \vdash \text{case}(E, E_1, E_2) : C
}$$
$\text{case}$ is another new term, just like the previous terms and injections (which are also terms).

The reduction of a case is as follows:
$$\begin{align*}
    \text{case}(\text{inj. } l, E_1, E_2) &\to E_1E \\
    \text{case}(\text{inj. } r, E_1, E_2) &\to E_2E
\end{align*}$$
Note that $E_1$ and $E_2$ are abstractions.

There is also **no** associativity in this. Nested choices or polytypes must be explicitly bracketed to show which way around it is.

We now need to deal with (equi-)recursive types. Let's try:
$$A, B ::= \varphi\ |\ A \dashv B\ |\ A + B\ |\ A \times B\ |\ X\ |\ \mu X . A$$

So for our lists, we can do something like $\text{list num} = (\ ) + (\text{num} \times \text{list num})$, and we can use $\mu$-equality to express it as $\mu X . (\ ) + (\text{num} \times X)$.

$\mu$-conversion is expressed as: $\mu X . A =_\mu A [\mu X . A / X]$, and $=_\mu$ is the smallest congruence relation on types that contains $=_\mu$-steps:
$$\dfrac{
    \Gamma \vdash E : A
}{
    \Gamma \vdash E : B
}\ (A =_\mu B)$$
If we express these recursive types as trees, two recursive types are $=_\mu$ equivalent if unfolding their infinite tree of types yield coinciding trees. Infinite unfolding is undefined.

With these, we can finally type self application:
![[SelfApp.png]]

We can also type the non-recursive $\mathbf{Y}$ combinator with this too:
$$\dfrac{
    \dfrac{
        \dfrac{
            \dfrac{\text{See RHS Tree}}{\Gamma' \vdash \lambda x . f (x x) : \mu X . X \to \varphi}\ (\to I)
        }{
            \Gamma' \vdash \lambda x . f (x x) : (\mu X . X \to \varphi) \to \varphi
        }\ (\mu)
        \hspace{2em}
        \dfrac{
            \dfrac{
                \dfrac{
                    \dfrac{
                        \dfrac{}{
                            \Gamma'' \vdash x : \mu X . X \to \varphi
                        }\ (A x)
                    }{
                        \Gamma'' \vdash x : (\mu X . X \to \varphi) \to \varphi
                    }\ (\mu)
                    \hspace{2em}
                    \dfrac{}{
                        \Gamma'' \vdash x : \mu X . X \to \varphi
                    }\ (A x)
                }{
                    \Gamma'' \vdash x x : \varphi
                }\ (\to E)
            }{
                (\Gamma'' = \Gamma', x : \mu X . X \to \varphi) \to \varphi
                \vdash
                f (x x) : \varphi
            }\ (\to E)
        }{
            \Gamma' \vdash \lambda x . f (x x) : \mu X . X \to \varphi
        }\ (\to I)
    }{
        (\Gamma' = f : \varphi \to \varphi)
        \vdash
        (\lambda x . f (x x)) (\lambda x . f ( x x))
        : \varphi
    }\ (\to E)
}{
    \emptyset \vdash \lambda f . (\lambda x . f (x x)) (\lambda x . f (x x)) : (\varphi \to \varphi) \to \varphi
}\ (\to I)$$

Iso-recursive types use fold and unfold type constructors. folding a type is hiding details, and unfolding is expanding the recursive type structure:
$$\dfrac{
    \Gamma \vdash E : \mu X . A
}{
    \Gamma \vdash \text{unfold}(E) : A [\mu X . A / X]
}\ (\text{unfold})$$
$$\dfrac{
    \Gamma \vdash E : A [\mu X . A / X]
}{
    \Gamma \vdash \text{fold}(E) : \mu X . A
}\ (\text{fold})$$
With all of this, a list can be expressed as:
$$[A] = \mu X . (\ ) + (A \times X)$$
So we have the following rules:
$$\dfrac{
    \dfrac{
        \dfrac{}{
            \Gamma \vdash [\ ] : (\ )
        }\ (\text{unit})
    }{
        \Gamma \vdash \text{inj. } l\ [\ ] : (\ ) + (A \times [A])
    }\ (\text{inj. } l)
}{
    \Gamma \vdash \text{fold}(\text{inj. } l\ [\ ]) : [A]
}\ (\text{fold})$$
$$\dfrac{
    \dfrac{
        \dfrac{
            \Gamma \vdash E_1 : A
            \hspace{2em}
            \Gamma \vdash E_2 : [A]
        }{
            \Gamma \vdash \left< E_1, E_2 \right> : A \times [A]
        }\ (\text{Pair})
    }{
        \Gamma \vdash \text{inj. } r : (\ ) + (A \times [A])
    }\ (\text{inj. } r)
}{
    \Gamma \vdash \text{fold}(\text{inj. } r\ \left< E_1, E_2 \right>) : [A]
}\ (\text{fold})$$
In that final rule, $\text{inj. }r$ acts as our $\text{Cons}$ function if done on pairs of items of a type and a list of items of that type.

# Approximation Semantics for $\Lambda$

We will give operational semantics to lambda terms called approximation semantics. We are studying how a term runs... ignoring all the active terms in it.
$$M, N ::= x\ |\ \lambda x . M\ |\ M N\ |\ \bot$$
$\bot$ helps us hide terms we aren't interested in.

The notion of reduction on lambda calculus with $\bot$ ($\to_\bot$) is a natural extension of reduction on lambda calculus:
- $\lambda x . \bot \to_\bot \bot$
- $\bot M \to_\bot \bot$

We'll first declare that $\bot$ is smaller than any term we will look at, so $\sqsubseteq : \bot \sqsubseteq M, \text{extended over terms}$. Note that $P \sqsubseteq Q \implies P R \sqsubseteq Q R$.

- Direct Approximant ($A \sqsubseteq M$, $A$ has the same structure as $M$ but contains $\bot$s):
    - Approximant: $A ::= x\ A_1\ \dots\ A_n\ (n \geq 0)\ |\ \lambda x . A\ (A \neq \bot)\ |\ \bot$.
- $\mathcal{A}(M) \triangleq \left\{ A \in \mathcal{A}\ |\ \exists N . M \to^* N \land A \sqsubseteq N \right\}$.

Note that we only are concerned if a term is an approximant if it is HNF-shaped, so something like self application applied to itself $(\lambda x . x x)(\lambda x . x x)$ will run to itself, so its sole approximant is $\bot$.

However, something like the $\mathbf{Y}$ combinator has an infinite number of approximants, we just keep taking an increasing number of applications of the function given to it onto $\bot$, so all of the approximants are sort of "HNF-shaped" (as $\bot$ is irreducible).

Note: $M =_\beta N \implies \mathcal{A}(M) = \mathcal{A}(N)$.
