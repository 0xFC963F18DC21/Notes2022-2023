### TSO (Redone)

Let $\mathtt{tso}$ be a strict partial order on all events on a graph $G$. $G$ is **TSO-*consistent*** with respect to $\mathtt{tso}$ if the following hold:

- $\mathtt{tso}$ is **total** on all non-read events in $G$. $\mathtt{tso}$ is allowed to be total on reads, but that is not a requirement.
- $G.\mathtt{po} \setminus (G.\mathtt{W} \times G.\mathtt{R}) \subseteq \mathtt{tso}$.
- $G.\mathtt{rf} \subseteq \mathtt{tso} \cup G.\mathtt{po}$ (which implies $G.\mathtt{rfe} \subseteq \mathtt{tso}$).
- $\left< w, r \right> \in G.\mathtt{rf} \implies (\neg \exists w' . w' \in G.\mathtt{W}_{\mathtt{loc}(r)} \implies \left< w, w' \right> \in \mathtt{tso} \land \left< w', r \right> \in \mathtt{tso} \cup G.\mathtt{po})$.

These are relatively similar to SC.

An execution $G$ is **TSO-*consistent*** if the following hold:

- $G$ is complete (all reads must read from a write).
- $G$ is TSO-consistent with respect to some strict partial order $\mathtt{tso}$ on $G.\mathtt{E}$.

![[TSOCsbex.png]]

### TSO (Alternative)

An execution $G$ is TSO-consistent if the following hold:
- $G$ is complete.
- There exists a modification order $\mathtt{mo}$ for $G$ such that:
    - $G.\mathtt{rfi} \cup \mathtt{rbi} \subseteq G.\mathtt{po}$ and $\text{acyclic}(\mathtt{ppo} \cup G.\mathtt{rfe} \cup \mathtt{mo} \cup \mathtt{rbe})$ holds.
    - Where $\mathtt{rb}$ is defined as before and $\mathtt{ppo} \triangleq (G.\mathtt{po} \setminus (G.\mathtt{W} \times G.\mathtt{R}))^{+}$ (preserved program order).
        - The transitive closure is taken in $\mathtt{ppo}$'s definition as removing the write-read arrows may break the transitivity of the execution.

![[tsoeq.png]]

And now... some even weaker models.

- SC is very expensive to implement in hardware.
- It also forbids various optimisations that are sound for sequential code.

What most hardware guarantees and compilers preserve is "SC-per-location" (a.k.a. coherence).

# Coherence

An execution graph $G$ is called *coherent* if the following hold:
- $G$ is complete.
- For every location $x$, there exists a strict total order $\mathtt{sc}_x$ on all accesses to $x$ such that:
    - If $\left< a, b \right> \in G.\mathtt{po}_x$ then $\left< a, b \right> \in \mathtt{sc}_x$.
    - If $\left< a, b \right> \in G.\mathtt{rf}_x$ then $\left< a, b \right> \in \mathtt{sc}_x$ and there does not exist $c \in G.\mathtt{WU}_x$ such that $\left< a, c \right> \in \mathtt{sc}_x$ and $\left< c, b \right> \in \mathtt{sc}_x$.

![[COHalt.png]]

## Bad Patterns

![[COHbp1.png]]

![[COHbp2.png]]

![[COHbp3.png]]

This is the weakest (sane) memory model possible. A sanity check, if you will. Pretty much all other implemented memory models are stronger than this... except Java's. Java's breaks **coherence-rr**.

![[COHalt2.png]]

## Problems

- COH is too weak for spin-locks to guarantee mutual exclusion.
- COH is too weak to add message-passing.

![[COHStr.png]]

So how do we mitigate this weak behaviour?
- Strengthen the notion of an "observed" write.
- In other words, make $\mathtt{rf}$-edges "synchronising".

This leads to a new memory model...

# Release / Acquire (RA)

![[RADef.png]]

![[RADefAlt.png]]

In summary, the ordering of strength in the models are:
$$COH < RA < TSO < SC$$
In other words:
$$\text{execs}(SC) \subset \text{execs}(TSO) \subset \text{execs}(RA) \subset \text{execs}(COH)$$
where $\text{execs}(MM)$ is the set of $MM$-consistent executions.

If $MM_1 < MM_2$ then:
- If an execution $G$ is $MM_2$-consistent, then it is also $MM_1$-consistent.
- If an execution $G$ is not $MM_1$-consistent, then it is also not $MM_2$-consistent.
