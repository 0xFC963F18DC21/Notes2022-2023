There are some finer subtleties for using `.notify_one()` and `.notify_all()`... going back to the bounded FIFO queue, you could make the argument to only `.notify_one()` if the queue was previously empty instead of `.notify_all()` every single enqueue.

That optimisation actually isn't really safe.

Take the following:

```
Queue is initially empty.

A: DEQ |- Waiting on queue to no longer be empty.
B: DEQ |

C: ENQ -- Enqueues something.
D: ENQ -- ... But D acquires the mutex right after C.

Now let's say A now dequeues whatever C has put in.
D did not call notify_one (as it was enqueueing onto a non-empty queue), meaning B never wakes up.

---

A: [Waiting...   ][Lock!][Dequeueing...]
                 ^
B: [Waiting...]  |
                 |- notify_one
C: [Enqueueing...]

D:               [Lock!][Enqueueing... it's non-empty, no notify!]
```

This optimisation works if we replace `.notify_one()` with `.notify_all()`... though how effective this optimisation is, is very questionable without any benchmarking.

# Atomics

Atomics are special variables that are performed with seeming atomicity (no splits can happen). These allow@
- Well-defined race conditions.
- Fine-grained synchronisation between threads.

C++ offers the `std::atomic<T>` template class for this. It is most commonly used for trivial integral, boolean or pointer types.

These define the following:
- `void store(T x)`: Store a value of the proper type.
- `T load()`: Returns the stored value of the proper type.
- `T exchange(T x)`: Store a new value, and return the old value.
- `bool compare_exchange_strong(T &expected, T desired)`: Compares the old value to some provided value, and if they are equal, then store the new desired value, and returns true. Otherwise, it stores the old value to expected (the expected parameter is a *non-const Lvalue reference*), and returns false.
- `bool compare_exchange_weak(T &expected T desired)`: Same as above, but is allowed to fail to assign even if the stored value matches the expected value. Has better performance in loops, and usecases in certain architectures that define `_strong` and `_weak` differently.

All of those operations are atomic (indivisible). Note that for larger, non-trivial types, atomics are usually implemented with locks (and in C++, require the `atomic` library to be linked with `-latomic`).

For integral types, extra operations are defined to do with simple arithmetic (`+` / `-`) and bitwise operations.

Please note that `x += 2` and `x = x + 2` are two different operations when atomics are involved due to operator overloading.

The idea is that atomic declarations allow legitimate race conditions to not be considered as data races.

You can now try to implement a parallel find. Given some large vector and some number of worker threads, does *any* element in the vector satisfy some predicate? (We need atomic booleans as write-write races are value-agnostic.)

# Theory

We will focus on the principles of concurrency.
.
- Start with idealised models of concurrent computations.
- Look at simplistic problems.
- Emphasise correctness over pragmatism.
- "Correctness may be theoretical, bit incorrectness has practical impact."

This is important as concurrency bugs are a PITA to debug.

# Designing Parallel Programs

## Parallel Primality Testing

- Let's print primes from 1 to 10^6, given:
	- A 10-core multiprocessor.
	- One thread per processor.

And our goal is to get as close to a 10x speedup possible.

We could try load-balancing, giving each thread 10^5 numbers to process... we got a ~3x speedup. Some issues however are that as the magnitude of numbers grow, primes become less dense and primes are also harder to test for. This makes the thread workload uneven and unpredictable.

We could try using a shared counter instead, where each thread takes the next value off the counter. This yields an incorrect answer as `++` is not an atomic operation, so some numbers are now considered multiple times as some threads can sometimes read off the same value while others are incrementing.

Now if only we can glue the read and write together... and we can (with either low-level atomic instructions, synchronisation or with atomic data structures)!

# Synchronisation Principle 1: Mutual Exclusion

Let's use an example. "Alice and Bob share a pond". Both Alice and Bob have pets... and their pets don't get along with each other. They both, however, want to bathe in the pond.

We can use mutual exclusion to remedy this, but we need to implement it in such a way that it works.

## Formalising the Problem

- There are two types of formal properties in async computations:
	- Safety Properties
		- "Nothing bad happens. Ever."
		- If it is violated, it is done by a ***finite*** computation.
		- If you can frame the property in some context of a finite time frame, it's probably a safety property.
	- Liveness Properties
		- "Something good happens eventually."
		- Cannot be violated by a finite computation (i.e. we can always run longer and see what happens).
		- If you can inject "eventually" into a property, it's probably a liveness property.

- Mutual Exclusion
	- Both pets are never in the pond simultaneously (SAFETY)
	- No deadlock happens (LIVENESS)

- Idea 1
	- Just look at the pond (smh my head)
	- This... won't work.
		- Both Alice and Bob can assume the pond is empty when it wasn't.
			- Perhaps trees were in the way, or they happened to look at the same time, etc..

- Threads can't see what other threads are doing.
- We need explicit communication in order to coordinate them.

- Idea 2:
	- Bob calls Alice to check (and vice-versa).
	- This still won't quite work.
		- This is a transient form of communication, not *permanent* (at least for the lifetime of the computation).
		- Alice or Bob may be busy, or the phone might be out of battery, or one is out shopping, etc..

- Message-passing doesn't really work for mutual exclusion.
- Recipient might not be listening... or be there at all.
- Communication must be persistent and non-transient.

Let's try the can protocol...

- Cans are placed on the windows of both Alice and Bob's window, where one yanks their one-way line in order to tell the other they want to communicate.

Nope.

- Cannot solve mutual exclusion with interrupts.
	- Sender sets fixed bit in receiver's space.
	- Receiver resets bit when ready.
	- Requires an unbounded number of bits (infeasible).

Let's use flags instead.

- Both Alice and Bob have flags, where they raise the flag when they want to release their pet to bathe, and they will check if the other's flag is down before doing so. They will lower the flag once their pet returns.
	- This works to implement mutual exclusion!
	- ... except if both decide to raise their flags at the same time. That's a deadlock.

What if we instead have Bob lower his flag while Alice's flag is up, and re-raise his flag when Alice's flag is lowered?

- This finally works with no deadlocks, as all flags are raised and lowered in the same order.

### Proof$^{tm}$ of Mutual Exclusion

- Assume both pets are in the pond. (Not a constructive proof, but it works here.)
	- Consider the last time Alice and Bob each looked at each others' flags before letting the pets in.
	- **Without loss of generality**, assume Alice was the last to look.

```
                     Alice raised her flag
                                |                    Alice's last look, pet released.
                                |                                    |
Time ---------------------------------------------------------------------------->
                |      |                          |
                |      |    Bob would not have raised his flag in this region.
Bob last raised flag.  |
        Bob's last look, and pet released.

Alice must have seen Bob's flag... contradiction.
```

### Proof of No Deadlocks

- If only one pet wants in, it gets in.
- Deadlock requires both continually trying to get in.
- If Bob sees Alice's flag, he backs off, gives her priority (imposing some order on "flag raising").

### Remarks

- Protocol is unfair:
	- This can lead to resource starvation, as Bob always yields to Alice's requests.
		- Bob's pet can possibly never get in the pond.
- Protocol uses **waiting**.
	- What if an exception occurs, like Bob dying before he lowers his flag when his pet comes out of the pond? His flag will never be lowered.

You can't have fairness, no deadlocks and mutual exclusion all at once. You can have a maximum of two.

### Moral

- Mutual exclusion cannot be solved by:
	- Transient communication.
	- Interrupts.
- But it can be solved with:
	- Shared synchronisation variables that can be read / written.

# Concurrency and Mutual Exclusion

... bad news. Mutual Exclusion = Sequential Execution. This is because only one thread can actually execute their critical section at a time.

## Why do we care?

We want to execute as much code as possible concurrently. More sequential parts means reduced performance. **Amdahl's Law** says that this speedup is not linear... which is rather obvious.

$$Speedup = \frac{1-thread\ time}{n-thread\ time}$$

But really, it's closer to:

$$Speedup = \frac{1}{1-p+\frac{p}{n}}$$
`1 - p` represents the sequential part. $\frac{p}{n}$ represents the parallel part.

### Example

- 10 processors.
- 60% conc, 40% seq.
	- How close to 10x speedup? **2.17x**
- 80% conc, 20% seq?
	- **3.57x**
- 99% conc, 1% seq?
	- **9.17x**

Other synchronisation paradigms are:

- Readers-Writers
- Producer-Consumer

See the book for more information.

# Why is this so hard?

You are welcome to try this yourself...

$$S_n = \frac{1}{1-p+\frac{p}{n}}$$

$$S_2 = \frac{1}{1-p+\frac{p}{2}}$$
So

$$S_n = \frac{n S_2}{2n + 2S_2 - 2 - nS_2}$$

... the derivation is left as an exercise for the reader.

# The Basics of Shared-Memory Concurrency

Alan Turing has shown what is, and what is not computable on a sequential machine. Currently, it is still the best model for this.

The Turing Machine is a mathematical model of computation, and what is (and what isn't) computable. Efficiency isn't relevant.

But what about a model for concurrent computation, and what is (and what isn't) concurrently computable, in shared memory?

## Foundations of Shared Memory

We need to ask some basic questions to understand modern multiprocessors...

What is the **weakest** form of shared memory?

## Memory Location (called a register in AMP, unrelated to CPU registers)

Holds a binary value.

## What are the weakest hardware memory instructions?

A read and write instruction from some single memory location that holds one bit of memory from some safe memory location. One thread reads, and one thread writes.

... all the way to a **wait-free implementation of Atomic Snapshots**. See chapter 4 of AMP.

Our goal is to enable syncrhonisation between an arbitrary number of threads.
Is memory read and memory write enough? No. We need atomicity (e.g. one solution is Read-Modify-Write instructions).

- RMW: Think of it as some object.
	- It holds some value.
	- It has a way to return the value, and replace it with the result of some other function applied to x.
	- And it also does it **atomically**, with no divisible steps.

Like:

```java
public class RMW<T> {
	private T item;

	public RMW(T item) {
		this.item = item;
	}

	public synchronized T read() {
		return this.item;
	}

	public synchronized T modify(UnaryOperator<T> fn) {
		T prev = this.item;
		this.item = fn.apply(prev);
		return prev;
	}

	// Weak RMW function, only synchronises between two threads.
	public synchronized T exchange(T newItem) {
		T prev = this.item;
		this.item = newItem;
		return prev;
	}
}
```

```java
public class RMWLocation extends RMW<Integer> {
	public RMWLocation(int init) {
		super(init);
	}

	public synchronized int fetchAndAdd(int a) {
		int prev = this.item;
		this.item = prev + a;
		return prev;
	}

	public synchronized boolean compareAndSet(int exp, int des) {
		if (this.value == exp) {
			this.value = des;
			return true;
		}

		return false;
	}
}
```

In real hardware, this took a while to appear. The first appearances only had exchange (IBM 360), fetch-and-add (NYU ultracomputer), swap (SPARCs).

We now understand their limitations, and all modern x86 processors support CAS (same with ARM).

# Concurrent Semantics: Sequential Consistency (SC)

Well, there's three models for this:

1. Sequential Consistency (SC) model (a.k.a. Interleaving semantics.)
	1. E.g. an idealised and simple model simulating a uniprocessor machine.
		1. The instructions of each thread are executed in order.
		2. Instructions of different threads can be interleaved arbitrarily.
	2. It's a good abstraction, especially for high-level reasoning.
	3. Not available on actual hardware.
	4. Inefficient, and extremely expensive to implement.
2. Hardware models
	1. Intel x86 has its own model.
	2. ARM has its own model, which is far more complicated than x86's.
3. Software models
	1. The C / C++ 2011 model, also known as the C11 model.
	2. The Java memory model.

2 and 3 are known as **weak** memory models. These show other (possibly counter-intuitive) behaviours not present in SC (a **strong** memory model).
