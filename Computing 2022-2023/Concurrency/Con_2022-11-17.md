# Atomics Continued

Sometimes, you may want to introduce intentional race conditions into your code to speed things up.

For example, when looking through a vector of objects for some object that matches a predicate, if we don't care which object is returned (as long as it satisfies the predicate), you can ignore synchronisation on the value that stores the reference of the object to be returned.

As long as writing that return value is an atomic action (by e.g. returning the index of that satisfying item instead of returning the item itself), it should still work. The item returned is non-deterministic given the same vector and predicate, but since we do not care about that, everything is fine.

# Remember Sequential Consistency?

Atomics are essentially enforcing Sequential Consistency onto the read/write operations by default. It is a relatively sensible default as it is very intuitive to think about.

It is, however, very slow in practice. A *lot* of memory barriers or similar mechanisms are required to enforce this.

It is fine if the performance is not critical.

The most relaxed memory order in C++ is `std::memory_order_relaxed`. This is the weakest memory setting, where its only guarantee is sequential consistency per location (think Coherence).

# Message-Passing with Release / Acquire

This is relatively common. What if a thread wants to prepare some data to send to another thread?

SC lets us easily achieve this... though it does use a very expensive memory barrier. Relaxed ordering will not allow something like that to occur, as the writes can be re-ordered.

We can use relaxed behaviours while still allowing this. Using the release / acquire method, we can do message passing more efficiently:
- The sender releases after writing data.
- The receiver acquires when reading the continuation condition.

So, we can modify our definition of "synchronization" in our data race definition, as it can now be achieved with:
- Mutexes.
- Acquire load reading from Release store.
- SC load reading from SC store.

For RMW instructions:
- SC is as normal.
- Relaxed is normal.
- Release-only is available: relax load, release store.
- Acquire-only is available: acquire load, relaxed store:
- Acquire-Release is sometimes available for true RMW operations (e.g. compare-exchange). It loads with Acquire and stores with Release.

Atomic operations on larger types requires locks. There is no way around doing this for implementing atomic operations for larger types at all.

Let's implement a few locks!

# Spin Locks

These don't actually call into the operating system, and just causes the thread to spin in a tight loop until they can acquire the lock.

These are great for:
- Code with short critical sections.
- Low contention situations.
(Any of those situations may be a good reason to use one of these.)

However, they have rather terrible worst-case behaviour. Hybrid locks exist as a mix between spin locks and locks that use OS system calls.

For all our locks, we assume that only the thread holding the lock will unlock the lock.

## Test-And-Set Spin Lock

Test-And-Set performs the following two actions atomically:
- Return the location's old value (test).
- Write 1 to a location (set).

This is a relatively simple RMW instruction available on *all* modern CPUs. C++ exposes this via `exchange`.

The state of this lock is just a singular bit.
- Locking it is done by repeatedly TSA-ing the bit until 0 is returned.
- Unlocking it is done by simply setting the bit to 0.

There is a problem.

If one thread has the lock, any other thread wanting to acquire the lock is essentially fighting over the lock, and since TAS is an atomic RMW operation, it invalidates the local cache for each thread every single time a thread calls a TAS.

So how do we fix this? Let's try tweaking this TAS lock a little.

## Test-And-Set Spin Lock with Local Spinning

What if we repeatedly load the cached copy of the lock state, and only do a TAS when the lock "looks" available?

This should hopefully reduce bus traffic and cache thrashing, as the caches are only invalidated if the lock is actually released.

So how is this actually implemented?

Just replace our while loop that calls `exchange` in our loop condition with a loop that essentially does:

```cpp
while (lock_bit.test_and_set()) {
    while (lock_bit.load()) { }
}
```

We still have another problem. What if we have a lot of threads locally spinning, then they *all* see that the lock has been released by someone else? Well, we still have the TAS fight... again.
