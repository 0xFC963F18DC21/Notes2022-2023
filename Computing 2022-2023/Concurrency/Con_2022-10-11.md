# Logistics

Both theory and practical aspects of Concurrent Programming will be covered here.

Azalea covers the theory.
Alastair covers the practical aspects.

All Tuesday lectures are in 145. All Thursday lectures are in 311.

Main languages used:

- C++
- Haskell (briefly)
- Rust (conceptually)

There are two courseworks: a practical coursework, and a theory coursework. They are group-submitted courseworks (max. 3 people)... but you can solo-submit courseworks if you want.

# Introduction

Moore's law dictates that transistor density doubles every ~18 months. In practice, however, it starts to break down in the early 2000s, and clock speeds plateaued. Especially since there are some physical limitations we need to contend with (chip size, quantum tunneling preventing transistors from becoming too small, etc.).

Clock speed also cannot be infinitely increased due to the power costs and the heat production will overwhelm modern cooling techniques for the chip.

So to deal with that, CPUs now gain extra cores (the Chip Multicore Processor) to use the extra transistors... **on the same chip**. Uniprocessors (single processor, single memory) and shared-memory processors (multiple processors with independent cache **on separate chips**, with one bus connecting one shared memory) are now extinct as a consequences.

We care because time no longer cures software bloat, and if you double your program's path length (***please insert some choice expletives against Electron and JavaScript here***), you can't just wait until processors get faster. Your software must exploit concurrency better.

Ideally, we want to mirror the scaling of single-core process with concurrency. However, things are not so simple as parallelisation and synchronisation require great care, with mutual exclusion and other things slowing down the actual performance. Resource management is also another such bottleneck in this equation.

So we need to think *concurrently*. In other words, thinking that many threads manipulate the same objects in memory instead of just one. We will, however, not deal with message-passing concurrency.

The difficulty of this comes from asynchrony (the threads not running in a deterministic order) due to such things like cache misses (!), page faults (**!!**) or lack of scheduling quantum leading to context switches (***!!!***).

We are using the following model:

![[CPUs.png]]

- Multiple threads within processes (where said threads are sometimes also called processes... confusingly).
- Single shared memory, split up into memory spaces per process, which threads within a process share.
- Objects live in memory.
- Unpredictable asynchronous delays.

We'll only be mainly talking about processors (at the hardware level), processes, and threads in processes.

# Practical Component 2a

Let's talk about Concurrency and Locks.

**Switch to code editor file!**
